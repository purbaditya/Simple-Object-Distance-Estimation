{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLICATION OF SIMPLE MACHINE LEARNING REGRESSION METHODS AND BASIC NEURAL NETWORKS\n",
    "TO A DISTANCE ESTIMATION PROBLEM ON THE KITTY OBJECT DETECTION DATASET. \n",
    "\n",
    "THE TRAINING DATA INCLUDE A SECTION OF THE INFORMATION (FEATURES) PROVIDED IN THE LABEL \n",
    "TXT FILES, CONVERTED TO A TABULAR REPRESENTATION. \n",
    "\n",
    "THE TRAINING IS PERFORMED INITIALLY WITH MULTIPLE FEATURES AS INPUT TO THE MODELS.\n",
    "\n",
    "THE LABEL IS TAKEN AS THE 'zloc' VARIABLE REPRESENTING THE DISTANCE OF THE OBJECT\n",
    "FROM THE CAMERA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, ElasticNet, Lasso, Ridge\n",
    "#from sklearn.svm import SVR, LinearSVR, NuSVR\n",
    "#from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "w = 1242\n",
    "h = 375\n",
    "d = 3\n",
    "cR = (0, 0, 255)\n",
    "cG = (0, 255, 0)\n",
    "cB = (255, 0, 0)\n",
    "cK = (0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DATA\n",
    "df = pd.read_csv('annotations.csv')\n",
    "#print(df.info()) # Display the information\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "idx = round(np.random.rand()*6492)\n",
    "file = df.iloc[idx,0]\n",
    "\n",
    "odf_file = df[df['filename']==file]\n",
    "\n",
    "#im = Image.open('images/training/image_2/'+file)\n",
    "#im.show()\n",
    "\n",
    "''' Check Images on bounding boxes\n",
    "im = cv2.imread('images/training/image_2/'+file.replace('.txt','.png'))\n",
    "res = im.copy()\n",
    "for id in range(len(odf_file)):\n",
    "    bbox = odf_file.iloc[id,5:9].to_numpy()\n",
    "    cv2.rectangle(res, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), cR, 2)\n",
    "\n",
    "cv2.imshow(\"Distance\", res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "odf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD ADDITIONAL FEATURES\n",
    "df['size'] = (df['xmax'] - df['xmin'])*(df['ymax'] - df['ymin'])/(h*w)\n",
    "df['volume'] = df['height']*df['width']*df['length']\n",
    "df['area'] = df['height']*df['width']\n",
    "\n",
    "df['xmin'] = df['xmin']/w\n",
    "df['xmax'] = df['xmax']/w\n",
    "df['ymin'] = df['ymin']/h\n",
    "df['ymax'] = df['ymax']/h\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER THE DATA IF A CERTAIN CLASS IS TO BE FILTERED AND CERTAIN ATTRIBUTES TO BE CORRECTED.\n",
    "# SKIP THIS TO TRAIN WITH ALL CLASSES\n",
    "df_class = df[df['class']=='Car'] # Filter cars\n",
    "df_class = df_class[df_class['occluded']<=1] # Filter not occluded cars\n",
    "df_class = df_class[df_class['zloc']>0] # Filter cars with positive zlocs\n",
    "df_class.info() # Display Info - Total number of examples to train with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = StandardScaler()\n",
    "#sc.fit_transform(df_class[['height','width','length']])\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "nuval = mm.fit_transform(df_class[['height','width','length','xloc','yloc','zloc','size','volume','area']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE THE LAST COLUMNS\n",
    "print('Maximum values before and after normalization')\n",
    "print(df_class['height'].abs().max())\n",
    "print(df_class['width'].abs().max())\n",
    "print(df_class['length'].abs().max())\n",
    "\n",
    "print(df_class['xloc'].abs().max())\n",
    "print(df_class['yloc'].abs().max(),'\\n')\n",
    "\n",
    "#print(df_class['zloc'].abs().min())\n",
    "#print(df_class['zloc'].abs().max(),'\\n')\n",
    "\n",
    "zlocmax = df_class['zloc'].abs().max()\n",
    "zlocmin = df_class['zloc'].abs().min()\n",
    "\n",
    "# create dataset for training\n",
    "ds_class = df_class.drop(columns=['class','truncated','occluded'])\n",
    "ds_class[['height','width','length','xloc','yloc','zloc','size','volume','area']] = nuval\n",
    "\n",
    "print(ds_class['height'].abs().max())\n",
    "print(ds_class['width'].abs().max())\n",
    "print(ds_class['length'].abs().max())\n",
    "\n",
    "print(ds_class['xloc'].abs().max())\n",
    "print(ds_class['yloc'].abs().max())\n",
    "\n",
    "# REMOVE FEATURES IF NECESSARY\n",
    "# ds_class.drop(columns=['observation angle','rot_y'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL DATASET FOR TRAINING\n",
    "ds_class.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "sns.scatterplot(ds_class,x=ds_class['size'],y=ds_class['zloc'],hue=ds_class['volume'])\n",
    "fig.suptitle('Object distance vs bbox size for different object volumes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET PREPARATION\n",
    "X = ds_class.drop(columns='zloc')\n",
    "y = ds_class['zloc']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "# print(X_test)\n",
    "\n",
    "Id = X_test['filename']\n",
    "Bboxes = X_test.iloc[:,2:6]\n",
    "Bboxes['xmin'] = Bboxes['xmin']*w\n",
    "Bboxes['xmax'] = Bboxes['xmax']*w\n",
    "Bboxes['ymin'] = Bboxes['ymin']*h\n",
    "Bboxes['ymax'] = Bboxes['ymax']*h\n",
    "\n",
    "X_train.drop(columns=['filename'],inplace=True)\n",
    "X_test.drop(columns=['filename'],inplace=True)\n",
    "\n",
    "print(Bboxes)\n",
    "print(Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR REGRESSORS\n",
    "LinReg = LinearRegression()\n",
    "SGDReg = SGDRegressor(learning_rate='adaptive',penalty='l2',alpha=0.0001,l1_ratio=0.0001, max_iter=100000,tol=1e-6)\n",
    "RReg = Ridge(alpha=0.001,solver='lsqr')\n",
    "LS = Lasso(alpha=0.0001,max_iter=10000,tol=1e-6)\n",
    "ENet = ElasticNet(alpha=0.00001,l1_ratio=0.001,max_iter=100000,tol=1e-6)\n",
    "\n",
    "LinReg.fit(X=X_train,y=y_train)\n",
    "SGDReg.fit(X=X_train,y=y_train)\n",
    "RReg.fit(X=X_train,y=y_train)\n",
    "LS.fit(X=X_train,y=y_train)\n",
    "ENet.fit(X=X_train,y=y_train)\n",
    "\n",
    "# MLP\n",
    "NN = MLPRegressor(hidden_layer_sizes=(100,20),activation='relu',learning_rate='adaptive',max_iter=10000,tol=1e-6,random_state=1)\n",
    "NN.fit(X=X_train,y=y_train)\n",
    "cfs = NN.coefs_\n",
    "print(cfs[0].shape)\n",
    "print(cfs[1].shape)\n",
    "print(cfs[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT WITH THE FITTED MODELS\n",
    "y_lr = abs(LinReg.predict(X=X_test))\n",
    "y_sg = abs(SGDReg.predict(X=X_test))\n",
    "y_rr = abs(RReg.predict(X=X_test))\n",
    "y_ls = abs(LS.predict(X=X_test))\n",
    "y_en = abs(ENet.predict(X=X_test))\n",
    "y_nn = abs(NN.predict(X=X_test))\n",
    "\n",
    "e_lr = mean_squared_error(y_true=y_test,y_pred=y_lr)\n",
    "e_sg = mean_squared_error(y_true=y_test,y_pred=y_sg)\n",
    "e_rr = mean_squared_error(y_true=y_test,y_pred=y_rr)\n",
    "e_ls = mean_squared_error(y_true=y_test,y_pred=y_ls)\n",
    "e_en = mean_squared_error(y_true=y_test,y_pred=y_en)\n",
    "e_nn = mean_squared_error(y_true=y_test,y_pred=y_nn)\n",
    "\n",
    "e = np.array([[e_lr,e_sg,e_rr,e_ls,e_en,e_nn]])\n",
    "edf = pd.DataFrame(e,index=['MSE'],columns=['LinReg','LinSGD','Ridge','Lasso','ElasticNet','MLP'])\n",
    "\n",
    "print('RESULTS')\n",
    "print('-----------------------------------------------------------------')\n",
    "print(edf,'\\n')\n",
    "\n",
    "y_o = np.concatenate([y_nn.reshape(-1,1)*(zlocmax-zlocmin)+zlocmin, y_test.to_numpy().reshape(-1,1)*(zlocmax-zlocmin)+zlocmin, Bboxes.values],axis=1)\n",
    "print(y_o.shape)\n",
    "\n",
    "# CREATE AND JOIN OUTPUT DATAFRAMES\n",
    "odf = pd.DataFrame(Id.values,columns=['filename'])\n",
    "tmpdf = pd.DataFrame(y_o,columns=['prediction (meters)','label (meters)','xmin','ymin','xmax','ymax'])\n",
    "\n",
    "odf = odf.join(tmpdf)\n",
    "odf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY EXAMPLES\n",
    "idx = round(np.random.rand()*6492)\n",
    "file = odf.iloc[idx,0]\n",
    "\n",
    "odf_file = odf[odf['filename']==file]\n",
    "print(odf_file)\n",
    "\n",
    "#im = Image.open('images/training/image_2/'+file)\n",
    "#im.show()\n",
    "im = cv2.imread('images/training/image_2/'+file.replace('.txt','.png'))\n",
    "res = im.copy()\n",
    "for id in range(len(odf_file)):\n",
    "    bbox = odf_file.iloc[id,3:].values\n",
    "    pred = str(round(odf_file.iloc[id,1]))\n",
    "    lab = str(round(odf_file.iloc[id,2]))\n",
    "    cv2.rectangle(res, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), cR, 1)\n",
    "    cv2.putText(res, pred+'|'+lab, (int(bbox[0]), int(bbox[1])),cv2.FONT_HERSHEY_PLAIN, 1, cR ,2)\n",
    "\n",
    "cv2.imshow(\"Distance\", res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN WITH REDUCED DATASET (ONLY BOUNDING BOX INFORMATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET PREPARATION\n",
    "X = ds_class.drop(columns='zloc')\n",
    "y = ds_class['zloc']\n",
    "\n",
    "Xr_train,Xr_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "# print(X_test)\n",
    "\n",
    "Id = Xr_test['filename']\n",
    "Bboxes = Xr_test.iloc[:,2:6]\n",
    "Bboxes['xmin'] = Bboxes['xmin']*w\n",
    "Bboxes['xmax'] = Bboxes['xmax']*w\n",
    "Bboxes['ymin'] = Bboxes['ymin']*h\n",
    "Bboxes['ymax'] = Bboxes['ymax']*h\n",
    "\n",
    "Xr_train.drop(columns=['filename','volume','area','height','width','length','xloc','yloc','rot_y','observation angle'],inplace=True)\n",
    "Xr_test.drop(columns=['filename','volume','area','height','width','length','xloc','yloc','rot_y','observation angle'],inplace=True)\n",
    "\n",
    "Xr_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR REGRESSORS\n",
    "rLinReg = LinearRegression()\n",
    "rSGDReg = SGDRegressor(loss='huber',learning_rate='adaptive',penalty='l2',alpha=0.0001,l1_ratio=0.0001, max_iter=100000,tol=1e-6)\n",
    "rRReg = Ridge(alpha=0.001,solver='lsqr')\n",
    "rLS = Lasso(alpha=0.0001,max_iter=10000,tol=1e-6)\n",
    "rENet = ElasticNet(alpha=0.00001,l1_ratio=0.001,max_iter=100000,tol=1e-6)\n",
    "\n",
    "rLinReg.fit(X=Xr_train,y=y_train)\n",
    "rSGDReg.fit(X=Xr_train,y=y_train)\n",
    "rRReg.fit(X=Xr_train,y=y_train)\n",
    "rLS.fit(X=Xr_train,y=y_train)\n",
    "rENet.fit(X=Xr_train,y=y_train)\n",
    "\n",
    "# MLP\n",
    "rNN = MLPRegressor(hidden_layer_sizes=(100,80,60,30),activation='relu',learning_rate='adaptive',max_iter=10000,tol=1e-6,random_state=1)\n",
    "rNN.fit(X=Xr_train,y=y_train)\n",
    "rcfs = rNN.coefs_\n",
    "for i in range(len(rcfs)):\n",
    "    print(rcfs[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT WITH THE FITTED MODELS\n",
    "ry_lr = abs(rLinReg.predict(X=Xr_test))\n",
    "ry_sg = abs(rSGDReg.predict(X=Xr_test))\n",
    "ry_rr = abs(rRReg.predict(X=Xr_test))\n",
    "ry_ls = abs(rLS.predict(X=Xr_test))\n",
    "ry_en = abs(rENet.predict(X=Xr_test))\n",
    "ry_nn = abs(rNN.predict(X=Xr_test))\n",
    "\n",
    "re_lr = mean_squared_error(y_true=y_test,y_pred=ry_lr)\n",
    "re_sg = mean_squared_error(y_true=y_test,y_pred=ry_sg)\n",
    "re_rr = mean_squared_error(y_true=y_test,y_pred=ry_rr)\n",
    "re_ls = mean_squared_error(y_true=y_test,y_pred=ry_ls)\n",
    "re_en = mean_squared_error(y_true=y_test,y_pred=ry_en)\n",
    "re_nn = mean_squared_error(y_true=y_test,y_pred=ry_nn)\n",
    "\n",
    "re = np.array([[re_lr,re_sg,re_rr,re_ls,re_en,re_nn]])\n",
    "redf = pd.DataFrame(re,index=['MSE'],columns=['LinReg','LinSGD','Ridge','Lasso','ElasticNet','MLP'])\n",
    "\n",
    "print('RESULTS')\n",
    "print('-----------------------------------------------------------------')\n",
    "print(redf,'\\n')\n",
    "\n",
    "ry_o = np.concatenate([ry_nn.reshape(-1,1)*(zlocmax-zlocmin)+zlocmin, y_test.to_numpy().reshape(-1,1)*(zlocmax-zlocmin)+zlocmin, Bboxes.values],axis=1)\n",
    "print(y_o.shape)\n",
    "\n",
    "# CREATE AND JOIN OUTPUT DATAFRAMES\n",
    "rodf = pd.DataFrame(Id.values,columns=['filename'])\n",
    "tmpdf = pd.DataFrame(ry_o,columns=['prediction (meters)','label (meters)','xmin','ymin','xmax','ymax'])\n",
    "\n",
    "rodf = rodf.join(tmpdf)\n",
    "rodf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY EXAMPLES\n",
    "idx = round(np.random.rand()*6492)\n",
    "file = rodf.iloc[idx,0]\n",
    "\n",
    "odf_file = rodf[rodf['filename']==file]\n",
    "print(odf_file)\n",
    "\n",
    "#im = Image.open('images/training/image_2/'+file)\n",
    "#im.show()\n",
    "im = cv2.imread('images/training/image_2/'+file.replace('.txt','.png'))\n",
    "res = im.copy()\n",
    "for id in range(len(odf_file)):\n",
    "    bbox = odf_file.iloc[id,3:].values\n",
    "    pred = str(round(odf_file.iloc[id,1]))\n",
    "    lab = str(round(odf_file.iloc[id,2]))\n",
    "    cv2.rectangle(res, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), cR, 1)\n",
    "    cv2.putText(res, pred+'|'+lab, (int(bbox[0]), int(bbox[1])),cv2.FONT_HERSHEY_DUPLEX, 1, cR ,2)\n",
    "\n",
    "cv2.imshow(\"Distance\", res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setuptools.dist # import setuptuls before distutils, avoids distutils error\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Input, ops\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "\n",
    "# Define custom functions if necessary\n",
    "def custom_lr_scheduler(epoch,lr):\n",
    "    if epoch < 100:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr/(1+epoch/1000000)\n",
    "    \n",
    "def custom_loss(label,pred):\n",
    "    difference = ops.square(label - pred)\n",
    "    return ops.sqrt(ops.mean(difference, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD AND TRAIN MODEL\n",
    "modelk = Sequential()\n",
    "modelk.add(Input(shape=(5,)))\n",
    "modelk.add(Dense(100, activation='relu'))\n",
    "modelk.add(BatchNormalization())\n",
    "modelk.add(Dense(5, activation='relu'))\n",
    "modelk.add(BatchNormalization())\n",
    "modelk.add(Dense(2, activation='relu'))\n",
    "modelk.add(BatchNormalization())\n",
    "modelk.add(Dense(1))\n",
    "\n",
    "ad_lr = keras.callbacks.LearningRateScheduler(custom_lr_scheduler)\n",
    "opt = Adam(learning_rate=5e-3)\n",
    "modelk.summary()\n",
    "modelk.compile(loss='huber', optimizer=opt)\n",
    "modelk.fit(Xr_train, y_train, epochs=2000, batch_size=512,verbose=1, callbacks=[ad_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE MODEL\n",
    "print(Xr_test)\n",
    "ry_nnk = abs(modelk.predict(Xr_test))\n",
    "re_nnk = mean_squared_error(y_true=y_test,y_pred=ry_nnk)\n",
    "print(re_nnk)\n",
    "\n",
    "ry_ok = np.concatenate([ry_nnk*(zlocmax-zlocmin)+zlocmin,y_test.to_numpy().reshape(-1,1)*(zlocmax-zlocmin)+zlocmin,Bboxes.values],axis=1)\n",
    "print(ry_ok.shape)\n",
    "\n",
    "# CREATE AND JOIN OUTPUT DATAFRAMES\n",
    "rodfk = pd.DataFrame(Id.values,columns=['filename'])\n",
    "tmpdf = pd.DataFrame(ry_ok,columns=['prediction (meters)','label (meters)','xmin','ymin','xmax','ymax'])\n",
    "\n",
    "rodfk = rodfk.join(tmpdf)\n",
    "rodfk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY EXAMPLES\n",
    "idx = round(np.random.rand()*6492)\n",
    "file = rodfk.iloc[idx,0]\n",
    "\n",
    "odf_file = rodfk[rodfk['filename']==file]\n",
    "print(odf_file)\n",
    "\n",
    "#im = Image.open('images/training/image_2/'+file)\n",
    "#im.show()\n",
    "im = cv2.imread('images/training/image_2/'+file.replace('.txt','.png'))\n",
    "res = im.copy()\n",
    "for id in range(len(odf_file)):\n",
    "    bbox = odf_file.iloc[id,3:].values\n",
    "    pred = str(round(odf_file.iloc[id,1]))\n",
    "    lab = str(round(odf_file.iloc[id,2]))\n",
    "    cv2.rectangle(res, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), cR, 1)\n",
    "    cv2.putText(res, pred+'|'+lab, (int(bbox[0]), int(bbox[1])),cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, cR ,2)\n",
    "\n",
    "cv2.imshow(\"Distance\", res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING PYTORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import Sequential,ReLU,SiLU,BatchNorm1d,Linear,HuberLoss,SmoothL1Loss,MSELoss\n",
    "import torch.utils.data as data_utils\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "# Convert datatables to torch tensors and load with DataLoader\n",
    "train = data_utils.TensorDataset(torch.tensor(Xr_train.values.astype('float32')), torch.tensor(y_train.values.astype('float32').reshape(-1,1)))\n",
    "train_loader = data_utils.DataLoader(train, batch_size=100, shuffle=True)\n",
    "Xr_test_torch = torch.tensor(Xr_test.values.astype('float32'))\n",
    "# y_test_torch = torch.tensor(y_test.values.astype('float32').reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD AND TRAIN MODELS\n",
    "modelt = Sequential(\n",
    "    Linear(5,100),\n",
    "    ReLU(),\n",
    "    BatchNorm1d(100),\n",
    "    Linear(100,5),\n",
    "    ReLU(),\n",
    "    BatchNorm1d(5),\n",
    "    Linear(5,2),\n",
    "    ReLU(),\n",
    "    BatchNorm1d(2),\n",
    "    Linear(2,1)\n",
    ")\n",
    "print(modelt,'\\n')\n",
    "\n",
    "loss_fn = HuberLoss()\n",
    "opt = optim.Adam(modelt.parameters(),lr=5e-3,betas=(0.9,0.999),eps=1e-16,weight_decay=0.0005)\n",
    "lr_scheduler = optim.lr_scheduler.ExponentialLR(opt,gamma=0.99)\n",
    "modelt.train()\n",
    "epochs = trange(1000)\n",
    "batchsize = 512\n",
    "total_loss = 0\n",
    "for epoch in epochs:\n",
    "    for X_batch,y_batch in train_loader:\n",
    "        y_pred = modelt(X_batch)\n",
    "        loss = loss_fn(y_pred,y_batch)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    lr_scheduler.step()\n",
    "    total_loss+= loss\n",
    "    epochs.set_description('Loss: ' + str(total_loss.detach().numpy()/(epoch+1)),refresh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE MODEL\n",
    "modelt.eval()\n",
    "ry_nnt = abs(modelt(Xr_test_torch).detach().numpy())\n",
    "re_nnt = mean_squared_error(y_true=y_test,y_pred=ry_nnt)\n",
    "print(re_nnt)\n",
    "\n",
    "ry_ot = np.concatenate([ry_nnt*(zlocmax-zlocmin)+zlocmin,y_test.to_numpy().reshape(-1,1)*(zlocmax-zlocmin)+zlocmin,Bboxes.values],axis=1)\n",
    "print(ry_ot.shape)\n",
    "\n",
    "# CREATE AND JOIN OUTPUT DATAFRAMES\n",
    "rodft = pd.DataFrame(Id.values,columns=['filename'])\n",
    "tmpdf = pd.DataFrame(ry_ot,columns=['prediction (meters)','label (meters)','xmin','ymin','xmax','ymax'])\n",
    "\n",
    "rodft = rodft.join(tmpdf)\n",
    "rodft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY EXAMPLES\n",
    "idx = round(np.random.rand()*6492)\n",
    "file = rodft.iloc[idx,0]\n",
    "\n",
    "odf_file = rodft[rodft['filename']==file]\n",
    "print(odf_file)\n",
    "\n",
    "#im = Image.open('images/training/image_2/'+file)\n",
    "#im.show()\n",
    "im = cv2.imread('images/training/image_2/'+file.replace('.txt','.png'))\n",
    "res = im.copy()\n",
    "for id in range(len(odf_file)):\n",
    "    bbox = odf_file.iloc[id,3:].values\n",
    "    pred = str(round(odf_file.iloc[id,1]))\n",
    "    lab = str(round(odf_file.iloc[id,2]))\n",
    "    cv2.rectangle(res, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), cR, 1)\n",
    "    cv2.putText(res, pred+'|'+lab, (int(bbox[0]), int(bbox[1])),cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, cR ,2)\n",
    "\n",
    "cv2.imshow(\"Distance\", res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kitti_dist_est",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
